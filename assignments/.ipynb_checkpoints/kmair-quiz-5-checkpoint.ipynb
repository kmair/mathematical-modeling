{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kanishk Mair (kmair@andrew.cmu.edu)\n",
    "Date: 2018-11-28 09:40:57.275880\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ASSIGNMENT: quiz-5\n",
    "- POINTS: 3\n",
    "- CATEGORY: quiz\n",
    "- RUBRIC: default\n",
    "- RUBRIC_CATEGORIES: technical, presentation\n",
    "- RUBRIC_WEIGHTS: 0.8, 0.2\n",
    "- DUEDATE: 2018-11-28 10:20:00\n",
    "- GRADER: John Kitchin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a quiz. You must be present in class to get credit for it. All your work must be your own, and turning this in means you agree that you worked alone on this assignment.**\n",
    "\n",
    "Newton's method is an iterative method based on finding roots using information about the derivative. There is an improvement if we use the Hessian shown below:\n",
    "\n",
    "$x_{n+1} = x_n - \\mathbf{H(x_n)}^{-1} \\mathbf{\\nabla f(x_n)}$\n",
    "\n",
    "where $\\mathbf{H(x_n)}$ is the Hessian matrix, and $\\nabla f(x_n)$ is the gradient of $f$ evaluated at $x_n$, which may be a vector. $f$ is a scalar function. This algorithm is still iterative, and starts from an initial guess.\n",
    "\n",
    "Use this information with autograd to find a minimum of the rosenbrock function starting at the point (5.0, 5.0). Verify you have found a minimum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrock(X):\n",
    "    x, y = X\n",
    "    return (1 - x)**2 + 100 * (y - x**2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value obtained using the modified Newton method is at: x = 1.000 and y = 1.000.\n",
      "The minimum value is 0.000.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from autograd import hessian\n",
    "from autograd import grad, elementwise_grad\n",
    "from numpy.linalg import inv\n",
    "\n",
    "H = hessian(rosenbrock)\n",
    "df = elementwise_grad(rosenbrock)  \n",
    "X0 = np.array([5., 5.])\n",
    "\n",
    "for i in range(15):\n",
    "    X = X0 - inv(H(X0)) @ df(X0)\n",
    "    X0 = X\n",
    "\n",
    "\n",
    "print(f'The minimum value obtained using the modified Newton method is at: x = {X0[0]:1.3f} and y = {X0[1]:1.3f}.')\n",
    "print(f'The minimum value is {rosenbrock(X0):1.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum value is at x = 1.000 and y = 1.000.\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "sol = minimize(rosenbrock, [5, 5])\n",
    "print(f'The minimum value is at x = {sol.x[0]:1.3f} and y = {sol.x[1]:1.3f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even the answer obtained from minimize is when x and y both equal 1. Thus we can verify that we have found a minimum."
   ]
  }
 ],
 "metadata": {
  "author": {
   "email": "kmair@andrew.cmu.edu",
   "name": "Kanishk Mair"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "org": {
   "ASSIGNMENT": "quiz-5",
   "CATEGORY": "quiz",
   "DUEDATE": "2018-11-28 10:20:00",
   "GRADER": "John Kitchin",
   "POINTS": "3",
   "RUBRIC": "default",
   "RUBRIC_CATEGORIES": "technical, presentation",
   "RUBRIC_WEIGHTS": "0.8, 0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
